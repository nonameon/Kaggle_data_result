{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Read all csv files to dataframe\n",
    "df_items = pd.read_csv(\"items.csv\")\n",
    "df_sales_train = pd.read_csv(\"sales_train.csv\")\n",
    "df_item_categories = pd.read_csv(\"item_categories.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_shops = pd.read_csv(\"shops.csv\")\n",
    "df_sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean irregular data\n",
    "df_sales_train = df_sales_train[(df_sales_train['item_price']<50000) & (df_sales_train['item_cnt_day']<1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative values\n",
    "df_sales_train = df_sales_train[df_sales_train['item_price'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We found repetitive names, so we can combine them\n",
    "df_sales_train.loc[df_sales_train.shop_id == 0,'shop_id']=57\n",
    "df_test.loc[df_test.shop_id == 0,'shop_id']=57\n",
    "df_sales_train.loc[df_sales_train.shop_id == 1,'shop_id']=58\n",
    "df_test.loc[df_test.shop_id == 1,'shop_id']=58\n",
    "df_sales_train.loc[df_sales_train.shop_id == 10,'shop_id']=11\n",
    "df_test.loc[df_test.shop_id == 10,'shop_id']=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the item_ID we want to predict\n",
    "df_sales_train = pd.merge(df_sales_train,df_items,how='left', on=['item_id'])\n",
    "df_sales_train.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the test ID we want to predict\n",
    "df_test['date_block_num'] = 34\n",
    "df_sales_train = pd.concat([df_sales_train,df_test],ignore_index=True,\n",
    "                        sort = False,keys = ['date_block_num','shop_id','item_id'])\n",
    "df_sales_train.fillna(0,inplace=True)\n",
    "df_sales_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"grid\" with columns\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in df_sales_train['date_block_num'].unique():\n",
    "    cur_shops = df_sales_train.loc[df_sales_train['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    cur_items = df_sales_train.loc[df_sales_train['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int16'))\n",
    "\n",
    "# Turn the grid into a dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a column with month count\n",
    "df_new = df_sales_train.groupby(index_cols,as_index=False)[\"item_cnt_day\"].sum()\n",
    "df_new = df_new.rename(columns = {\"item_cnt_day\": \"target\"})\n",
    "all_data = pd.merge(grid, df_new, how='left', on=index_cols).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a column with mean encoded shop_id\n",
    "df_new = df_sales_train.groupby(['shop_id', 'date_block_num'],as_index=False)[\"item_cnt_day\"].sum()\n",
    "df_new = df_new.rename(columns = {\"item_cnt_day\": \"target_shop\"})\n",
    "all_data = pd.merge(all_data, df_new, how='left', on=['shop_id', 'date_block_num']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a column with mean encoded item_id\n",
    "df_new = df_sales_train.groupby(['item_id', 'date_block_num'],as_index=False)[\"item_cnt_day\"].sum()\n",
    "df_new = df_new.rename(columns = {\"item_cnt_day\": \"target_item\"})\n",
    "all_data = pd.merge(all_data, df_new, how='left', on=['item_id', 'date_block_num']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del grid, df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Names of new columns\n",
    "cols_to_rename = list(all_data.columns.difference(index_cols)) \n",
    "cols_to_rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_range = [1, 2, 3, 4, 5, 12]\n",
    "\n",
    "for month_shift in shift_range:\n",
    "\n",
    "    train_shift = all_data[index_cols + cols_to_rename].copy()\n",
    "    \n",
    "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "    \n",
    "    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "    all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n",
    "\n",
    "del train_shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't use old data from year 2013\n",
    "all_data = all_data[all_data['date_block_num'] >= 12] \n",
    "\n",
    "\n",
    "# We will drop these at fitting stage\n",
    "to_drop_cols = ['target', 'target_shop', 'target_item', 'date_block_num']\n",
    "\n",
    "# Category for each item\n",
    "item_category_mapping = df_items[['item_id','item_category_id']].drop_duplicates()\n",
    "\n",
    "all_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\n",
    "all_data.to_pickle(\"data.pkl\")\n",
    "del all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/Split\n",
    "#For a sake of the programming assignment, let's artificially split the data into train and test. We will treat last month data as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save `date_block_num`, as we can't use them as features, but will need them to split the dataset into parts \n",
    "all_data = pd.read_pickle(\"data.pkl\")\n",
    "dates = all_data['date_block_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_train = dates[dates < 34]\n",
    "dates_target  = dates[dates == 34]\n",
    "\n",
    "X_train = all_data.loc[dates <  34].drop(to_drop_cols, axis=1)\n",
    "X_test =  all_data.loc[dates == 34].drop(to_drop_cols, axis=1)\n",
    "\n",
    "y_train = all_data.loc[dates <  34, 'target'].values\n",
    "y_test =  all_data.loc[dates == 34, 'target'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will run linear regression on numeric columns and get predictions for the last month.\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train.values, y_train)\n",
    "pred_lr = lr.predict(X_test.values)\n",
    "df_new = pd.DataFrame(pred_lr)\n",
    "df_sample_submission[\"item_cnt_month\"] = df_new\n",
    "#we create a filter for values bigger than 20 or smaller than 0\n",
    "df_sample_submission[\"item_cnt_month\"] = df_sample_submission[\"item_cnt_month\"].where(df_sample_submission[\"item_cnt_month\"] < 20, 20)\n",
    "df_sample_submission[\"item_cnt_month\"] = df_sample_submission[\"item_cnt_month\"].where(df_sample_submission[\"item_cnt_month\"] > 0, 0)\n",
    "df_sample_submission.to_csv('lr_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb model\n",
    "lgb_params = {\n",
    "\n",
    "            'feature_fraction': 0.75,\n",
    "            'metric': 'rmse',\n",
    "           'nthread':1, \n",
    "           'min_data_in_leaf': 2**7, \n",
    "           'bagging_fraction': 0.75, \n",
    "           'learning_rate': 0.03, \n",
    "           'objective': 'mse', \n",
    "           'bagging_seed': 2**7, \n",
    "           'num_leaves': 2**7,\n",
    "           'bagging_freq':1,\n",
    "           'verbose':0 \n",
    "          }\n",
    "\n",
    "model = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), 100)\n",
    "pred_lgb = model.predict(X_test)\n",
    "df_new = pd.DataFrame(pred_lgb)\n",
    "df_sample_submission[\"item_cnt_month\"] = df_new\n",
    "\n",
    "df_sample_submission[\"item_cnt_month\"] = df_sample_submission[\"item_cnt_month\"].where(df_sample_submission[\"item_cnt_month\"] < 20, 20)\n",
    "df_sample_submission[\"item_cnt_month\"] = df_sample_submission[\"item_cnt_month\"].where(df_sample_submission[\"item_cnt_month\"] > 0, 0)\n",
    "\n",
    "df_sample_submission.to_csv('lgb_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_level2 = np.c_[pred_lr, pred_lgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get target for the 2nd level dataset\n",
    "y_train_level2 = y_train[dates_train.isin([27, 28, 29, 30, 31, 32, 33])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And here we create 2nd level feeature matrix, init it with zeros first\n",
    "X_train_level2 = np.zeros([y_train_level2.shape[0], 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training with metafeatures\n",
    "xposition = 0 \n",
    "# Now fill `X_train_level2` with metafeatures\n",
    "for cur_block_num in [27, 28, 29, 30, 31, 32, 33]:\n",
    "    \n",
    "    X_train = all_data.loc[dates <  cur_block_num].drop(to_drop_cols, axis=1)\n",
    "    X_test =  all_data.loc[dates == cur_block_num].drop(to_drop_cols, axis=1)\n",
    "\n",
    "    y_train = all_data.loc[dates <  cur_block_num, 'target'].values\n",
    "\n",
    "    lr.fit(X_train.values, y_train)\n",
    "    pred_lr = lr.predict(X_test.values)\n",
    "    \n",
    "    model = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), 100)\n",
    "    pred_lgb = model.predict(X_test)\n",
    "    \n",
    "    dates_train_level2 = np.c_[pred_lr, pred_lgb] \n",
    "    \n",
    "    X_train_level2[xposition:(xposition + X_test.shape[0])]=dates_train_level2\n",
    "    xposition = xposition + X_test.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple convex mix\n",
    "alphas_to_try = np.linspace(0, 1, 1001)\n",
    "\n",
    "error = 1000\n",
    "for a in alphas_to_try:\n",
    "    mix = a * X_train_level2[:,0] + (1 - a) * X_train_level2[:,1]\n",
    "    mse = sklearn.metrics.mean_squared_error(mix, y_train_level2)\n",
    "    if mse < error:\n",
    "        best_alpha = a\n",
    "        r2_train_simple_mix = sklearn.metrics.r2_score(y_train_level2, mix)\n",
    "        error = mse\n",
    "\n",
    "print('Best alpha: %f; Corresponding r2 score on train: %f' % (best_alpha, r2_train_simple_mix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = best_alpha * X_test_level2[:,0] + (1 - best_alpha) * X_test_level2[:,1]\n",
    "#r2_test_simple_mix = sklearn.metrics.r2_score(y_test, test_preds)\n",
    "df_new = pd.DataFrame(test_preds)\n",
    "df_sample_submission[\"item_cnt_month\"] = df_new\n",
    "\n",
    "df_sample_submission[\"item_cnt_month\"] = df_sample_submission[\"item_cnt_month\"].where(df_sample_submission[\"item_cnt_month\"] < 20, 20)\n",
    "df_sample_submission[\"item_cnt_month\"] = df_sample_submission[\"item_cnt_month\"].where(df_sample_submission[\"item_cnt_month\"] > 0, 0)\n",
    "\n",
    "df_sample_submission.to_csv('mix_preds.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking\n",
    "lr.fit(X_train_level2, y_train_level2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = lr.predict(X_test_level2)\n",
    "\n",
    "df_new = pd.DataFrame(test_preds)\n",
    "df_new.head()\n",
    "df_sample_submission[\"item_cnt_month\"] = df_new\n",
    "\n",
    "df_sample_submission[\"item_cnt_month\"] = df_sample_submission[\"item_cnt_month\"].where(df_sample_submission[\"item_cnt_month\"] < 20, 20)\n",
    "df_sample_submission[\"item_cnt_month\"] = df_sample_submission[\"item_cnt_month\"].where(df_sample_submission[\"item_cnt_month\"] > 0, 0)\n",
    "\n",
    "df_sample_submission.to_csv('stacking_preds.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
